{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import data\n",
    "import os\n",
    "import parse\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seeds = deque([\"http://stackexchange.com/\"])\n",
    "searches = data.searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfsCrawl(frontier, iterations):\n",
    "    frontier = deque(frontier)\n",
    "    lowLim, uppLim = 3/5, 4/5\n",
    "    i, numVisited, urlVisited = 0, 0, set()\n",
    "    while frontier and i < iterations:\n",
    "        url = frontier.popleft()\n",
    "        urlVisited.add(url)\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "        except:\n",
    "            continue\n",
    "        host = parse.getDomain(url)\n",
    "        topics = parse.parseKeywords(resp)\n",
    "        for topic in topics:\n",
    "            for search in searches:\n",
    "                try:\n",
    "                    score = similarity.getSim(search, topic)\n",
    "                    if lowLim < score < highLim:\n",
    "                        print(str((score, search, topic, url)))\n",
    "                except:\n",
    "                    continue\n",
    "        frontier.extend(deque(parse.parseLinks(resp) - urlVisited))\n",
    "        numVisited += 1\n",
    "        i += 1\n",
    "    return (len(frontier), numVisited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dfsCrawl(stack, iterations):\n",
    "    stack = deque(stack)\n",
    "    lowLim, uppLim = 3/5, 4/5\n",
    "    depthMax, lastHost = 3, \"\"\n",
    "    depthLeft = depthMax\n",
    "    i, numVisited, urlVisited = 0, 0, set()\n",
    "    while stack and i < iterations:\n",
    "        url = stack.pop()\n",
    "        urlVisited.add(url)\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "        except:\n",
    "            continue\n",
    "        topics = parse.parseKeywords(resp)\n",
    "        for topic in topics:\n",
    "            for search in searches:\n",
    "                try:\n",
    "                    score = similarity.getSim(search, topic)\n",
    "                    if lowLim < score < highLim:\n",
    "                        print(str((score, search, topic, url))) # why not printed?\n",
    "                except:\n",
    "                    continue\n",
    "        host = parse.getDomain(url)\n",
    "        if host == lastHost:\n",
    "            if depthLeft:\n",
    "                depthLeft -= 1\n",
    "                stack.extend(deque(parse.parseLinks(resp)))\n",
    "            else:\n",
    "                depthLeft = depthMax\n",
    "        else:\n",
    "            depthLeft = depthMax\n",
    "            stack.extend(deque(parse.parseLinks(resp) - urlVisited))\n",
    "        numVisited += 1\n",
    "        i += 1\n",
    "    return (len(stack), numVisited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    iterList = [# 5, 10,\n",
    "                50, 100, 500]\n",
    "    for iterations in iterList:\n",
    "        print(\"Iterations: %d\" % iterations)\n",
    "        print()\n",
    "        '''\n",
    "        start = time.time()\n",
    "        try:\n",
    "            queueSize, bfsnumVisited = bfsCrawl(seeds, iterations)\n",
    "            print(\"Size of Queue: %d\" % queueSize)\n",
    "            print(\"Number of Visited: %d\" % bfsnumVisited)\n",
    "            print(\"Time Taken: %f\" % (time.time() - start))\n",
    "            print()\n",
    "        except Exception as inst:\n",
    "            print(\"BFS: %s\" % str(inst))\n",
    "            print()\n",
    "        '''\n",
    "        start = time.time()\n",
    "        try:\n",
    "            stackSize, dfsnumVisited = dfsCrawl(seeds, iterations)\n",
    "            print(\"Size of Stack: %d\" % stackSize)\n",
    "            print(\"Number of Visited: %d\" % dfsnumVisited)\n",
    "            print(\"Time Taken: %f\" % (time.time() - start))\n",
    "            print()\n",
    "        except Exception as inst:\n",
    "            print(\"DFS: %s\" % str(inst))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 50\n",
      "\n",
      "Size of Stack: 6096\n",
      "Number of Visited: 50\n",
      "Time Taken: 411.113517\n",
      "\n",
      "Iterations: 100\n",
      "\n",
      "Size of Stack: 10787\n",
      "Number of Visited: 100\n",
      "Time Taken: 819.840771\n",
      "\n",
      "Iterations: 500\n",
      "\n",
      "Size of Stack: 26864\n",
      "Number of Visited: 500\n",
      "Time Taken: 1881.018762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Iterations: 5\n",
    "\n",
    "Size of Queue: 1205\n",
    "Number of Visited: 5\n",
    "Time Taken: 65.640972\n",
    "\n",
    "Size of Stack: 923\n",
    "Number of Visited: 5\n",
    "Time Taken: 47.394564\n",
    "\n",
    "Iterations: 10\n",
    "\n",
    "Size of Queue: 2310\n",
    "Number of Visited: 10\n",
    "Time Taken: 134.098501\n",
    "\n",
    "Size of Stack: 1399\n",
    "Number of Visited: 10\n",
    "Time Taken: 64.906949\n",
    "\n",
    "Iterations: 50\n",
    "\n",
    "Size of Queue: 9522\n",
    "Number of Visited: 50\n",
    "Time Taken: 535.173888\n",
    "\n",
    "Size of Stack: 6096\n",
    "Number of Visited: 50\n",
    "Time Taken: 411.113517\n",
    "\n",
    "Iterations: 100\n",
    "\n",
    "Size of Queue: 19770\n",
    "Number of Visited: 100\n",
    "Time Taken: 1071.777788\n",
    "\n",
    "Size of Stack: 10787\n",
    "Number of Visited: 100\n",
    "Time Taken: 819.840771\n",
    "\n",
    "Iterations: 500\n",
    "\n",
    "Size of Queue: 68615\n",
    "Number of Visited: 500\n",
    "Time Taken: 4459.348122\n",
    "\n",
    "Size of Stack: 26864\n",
    "Number of Visited: 500\n",
    "Time Taken: 1881.018762\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bfsCrawlWrite(frontier, iterations):\n",
    "    frontier = deque(frontier)\n",
    "    relevant, threshold = [], 2/3\n",
    "    indent1 = 0, ' ' * 2\n",
    "    indent2, indent3 = indent1 * 2, indent1 * 3\n",
    "    indent4 = indent2 * 2\n",
    "    i = 0\n",
    "    with open('similarity.json', 'w') as f:\n",
    "        f.write('[\\n%s[\\n%s\"\"' % (indent1, indent2))\n",
    "        while frontier and i < iterations:\n",
    "            f.write(',\\n%s{\\n' % (indent2))\n",
    "            url = frontier.popleft()\n",
    "            resp = requests.get(url)\n",
    "            topics = parse.parseKeywords(resp)\n",
    "            f.write('%s\"\": \"\"' % (indent3))\n",
    "            for topic in topics:\n",
    "                relevant = False\n",
    "                stringBuilder = []\n",
    "                stringBuilder.append(',\\n%s\"%s\": [\\n' % (indent3, topic))\n",
    "                for search in searches:\n",
    "                    try:\n",
    "                        score = similarity.getSim(search, topic)\n",
    "                        if score >= threshold:\n",
    "                            relevant = True\n",
    "                            stringBuilder.append('%s\"(%s, %s)\",\\n' % (indent4, search, score))\n",
    "                    except:\n",
    "                        continue\n",
    "                if relevant:\n",
    "                    stringBuilder[-1] = stringBuilder[-1].rstrip()[:-1]\n",
    "                    stringBuilder.append('\\n')\n",
    "                    f.write(''.join(stringBuilder))\n",
    "                    f.write('%s]' % (indent3))\n",
    "            frontier.extend(deque(parse.parseLinks(resp)))\n",
    "            f.write('\\n%s}\\n%s]' % (indent2, indent1))\n",
    "            if frontier and i < iterations:\n",
    "                f.write(',')\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "        f.write('\\n]')\n",
    "    f.close()\n",
    "    return len(frontier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
